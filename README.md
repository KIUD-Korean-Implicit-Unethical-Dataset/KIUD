# KIUD

- Kosbi( https://github.com/naver-ai/korean-safety-benchmarks ) 
- KOLD ( https://github.com/boychaboy/kold ) 
- 욕설 감지 데이터셋 ( https://github.com/2runo/Curse-detection-data )
  
을 활용하여 구축한 한국어 암시적 비윤리 데이터셋입니다. 


- 성별, 성적 지향, 연령(세대), 국적 (인종), 외양, 출신지를 대상으로 하는 언어 표현 중
- 암시적인 키워드가 포함되지 않은 비윤리적 문장

만을 수집하였습니다. 

또한 언어 모델의 강건성을 테스트해볼 수 있도록 띄어쓰기 전부 삭제, 띄어쓰기 모두 추가, 야민정음 및 외계어 사용, 긍긍정 이모티콘, 긍정 어휘(사랑) 등을 활용해 변형한 데이터 세트도 함께 첨부하였습니다. 

최종 데이터셋 분포는 다음과 같습니다. 

<img width="349" alt="image" src="https://github.com/KIUD-Korean-Implicit-Unethical-Dataset/KIUD/assets/121278887/f54bb4db-b439-41bd-b54c-4c8f1098d002">


데이터셋과 관련된 문의가 있으시다면 kiudproject@gmail.com 로 편하게 연락 주세요 😊
